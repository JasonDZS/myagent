#!/usr/bin/env python3
"""
ç ”ç©¶æ™ºèƒ½ä½“æ¼”ç¤º

åŸºäº Deep Agents æ¶æ„çš„å…¨åŠŸèƒ½ç ”ç©¶æ™ºèƒ½ä½“ï¼Œé›†æˆï¼š
1. ç½‘ç»œæœç´¢ (SERPER API)
2. å­¦æœ¯æœç´¢ (arXiv, PubMed)
3. æ•°æ®åˆ†æ (pandas, numpy)
4. ç½‘é¡µå†…å®¹æŠ“å–å’Œåˆ†æ
5. Deep Agents å®Œæ•´æ¶æ„

ç¤ºä¾‹ä¸»é¢˜ï¼š"LLMçš„å‘å±•å†ç¨‹"
"""

import asyncio
import argparse
import os
import sys
from datetime import datetime
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from myagent.middleware.deep_agent import create_deep_agent
from myagent.tool.base_tool import BaseTool, ToolResult
from myagent.tool.web_search import create_search_tools
from myagent.tool.academic_search import create_academic_tools
from myagent.tool.data_analysis import create_data_analysis_tools
from myagent.tool.web_content import create_web_content_tools
from myagent.tool.code_execution import create_code_execution_tools
from myagent.trace import get_trace_manager, TraceExporter, TraceQueryEngine


async def create_research_agent():
    """åˆ›å»ºé›†æˆæ‰€æœ‰å·¥å…·çš„ç ”ç©¶æ™ºèƒ½ä½“"""
    
    # æ”¶é›†æ‰€æœ‰å·¥å…·
    tools = []
    
    try:
        # ç½‘ç»œæœç´¢å·¥å…· (SERPER API)
        tools.extend(create_search_tools())
        print("âœ… å·²åŠ è½½ç½‘ç»œæœç´¢å·¥å…· (SERPER API)")
    except Exception as e:
        print(f"âš ï¸ ç½‘ç»œæœç´¢å·¥å…·åŠ è½½å¤±è´¥: {e}")
    
    try:
        # å­¦æœ¯æœç´¢å·¥å…· (arXiv, PubMed)
        tools.extend(create_academic_tools())
        print("âœ… å·²åŠ è½½å­¦æœ¯æœç´¢å·¥å…· (arXiv, PubMed)")
    except Exception as e:
        print(f"âš ï¸ å­¦æœ¯æœç´¢å·¥å…·åŠ è½½å¤±è´¥: {e}")
    
    try:
        # æ•°æ®åˆ†æå·¥å…· (pandas, numpy)
        tools.extend(create_data_analysis_tools())
        print("âœ… å·²åŠ è½½æ•°æ®åˆ†æå·¥å…· (pandas, numpy)")
    except Exception as e:
        print(f"âš ï¸ æ•°æ®åˆ†æå·¥å…·åŠ è½½å¤±è´¥: {e}")
    
    try:
        # ç½‘é¡µå†…å®¹åˆ†æå·¥å…· (BeautifulSoup)
        tools.extend(create_web_content_tools())
        print("âœ… å·²åŠ è½½ç½‘é¡µå†…å®¹åˆ†æå·¥å…· (BeautifulSoup)")
    except Exception as e:
        print(f"âš ï¸ ç½‘é¡µå†…å®¹åˆ†æå·¥å…·åŠ è½½å¤±è´¥: {e}")

    try:
        # ä»£ç æ‰§è¡Œå·¥å…·
        tools.extend(create_code_execution_tools())
        print("âœ… å·²åŠ è½½ä»£ç æ‰§è¡Œå·¥å…· (Python)")
    except Exception as e:
        print(f"âš ï¸ ä»£ç æ‰§è¡Œå·¥å…·åŠ è½½å¤±è´¥: {e}")

    print(f"\nğŸ”§ æ€»è®¡åŠ è½½ {len(tools)} ä¸ªå·¥å…·")
    
    # åˆ›å»ºDeep Agentï¼Œé›†æˆæ‰€æœ‰å·¥å…·
    agent = create_deep_agent(
        tools=tools,
        name="research_agent",
        description="å…¨åŠŸèƒ½ç ”ç©¶æ™ºèƒ½ä½“ï¼Œé›†æˆç½‘ç»œæœç´¢ã€å­¦æœ¯æœç´¢ã€æ•°æ®åˆ†æå’Œå†…å®¹æŠ“å–"
    )
    
    # è®¾ç½®åˆé€‚çš„æœ€å¤§æ­¥æ•°
    agent.max_steps = 15
    
    return agent


async def run_comprehensive_research(topic: str = "LLMçš„å‘å±•å†ç¨‹"):
    """è¿è¡Œç»¼åˆç ”ç©¶æ¼”ç¤º"""
    
    print("ğŸ”¬ ç ”ç©¶æ™ºèƒ½ä½“æ¼”ç¤º")
    print("=" * 80)
    print("ğŸ“‹ æ¼”ç¤ºåŠŸèƒ½:")
    print("âœ… ç½‘ç»œæœç´¢ (SERPER API)")
    print("âœ… å­¦æœ¯æ–‡çŒ®æœç´¢ (arXiv, PubMed)")
    print("âœ… æ•°æ®åˆ†æå’Œè¶‹åŠ¿ (pandas, numpy)")
    print("âœ… ç½‘é¡µå†…å®¹æŠ“å– (BeautifulSoup)")
    print("âœ… ä»£ç æ‰§è¡Œ (Python)")
    print("âœ… Deep Agents å®Œæ•´æ¶æ„")
    print("=" * 80)
    
    # åˆ›å»ºç ”ç©¶æ™ºèƒ½ä½“
    agent = await create_research_agent()
    
    # è¯¦ç»†çš„ç ”ç©¶ä»»åŠ¡
    research_task = f"""
è¯·å¯¹"{topic}"è¿›è¡Œå…¨é¢æ·±å…¥çš„ç ”ç©¶åˆ†æï¼Œè¦æ±‚ï¼š

## ç ”ç©¶ç›®æ ‡
åˆ›å»ºä¸€ä»½ä¸“ä¸šçš„ç ”ç©¶æŠ¥å‘Šï¼Œæ¶µç›–æŠ€æœ¯å‘å±•ã€å­¦æœ¯è¿›å±•ã€å¸‚åœºè¶‹åŠ¿å’Œæœªæ¥å±•æœ›ã€‚

## å…·ä½“ä»»åŠ¡

### 1. ç ”ç©¶è§„åˆ’ (ä½¿ç”¨ write_todos å·¥å…·)
- åˆ¶å®šè¯¦ç»†çš„ç ”ç©¶è®¡åˆ’å’Œæ—¶é—´çº¿
- åˆ†è§£ä»»åŠ¡ä¸ºå¯ç®¡ç†çš„æ­¥éª¤
- è®¾å®šä¼˜å…ˆçº§å’Œä¾èµ–å…³ç³»

### 2. ç½‘ç»œä¿¡æ¯æ”¶é›† (ä½¿ç”¨ web_search å·¥å…·)
- æœç´¢æœ€æ–°çš„è¡Œä¸šæŠ¥å‘Šå’Œå¸‚åœºåˆ†æ
- æ”¶é›†æŠ€æœ¯å‘å±•è¶‹åŠ¿ä¿¡æ¯
- è·å–æƒå¨åª’ä½“çš„ç›¸å…³æŠ¥é“

### 3. å­¦æœ¯æ–‡çŒ®ç ”ç©¶ (ä½¿ç”¨ arxiv_search å·¥å…·)
- æœç´¢ç›¸å…³çš„å­¦æœ¯è®ºæ–‡å’Œé¢„å°æœ¬
- åˆ†ææŠ€æœ¯çªç ´å’Œç ”ç©¶æ–¹å‘
- æ”¶é›†å¼•ç”¨æ•°æ®å’Œå½±å“åŠ›æŒ‡æ ‡

### 4. æ•°æ®åˆ†æ (ä½¿ç”¨ analyze_data å·¥å…·)
- åˆ†ææŠ€æœ¯å‘å±•è¶‹åŠ¿æ•°æ®
- è¿›è¡Œç»Ÿè®¡åˆ†æå’Œç›¸å…³æ€§åˆ†æ
- ç”Ÿæˆæ•°æ®é©±åŠ¨çš„æ´å¯Ÿ

### 5. ä»£ç æ‰§è¡Œå’Œè®¡ç®— (ä½¿ç”¨ execute_code å·¥å…·)
- ç¼–å†™Pythonä»£ç è¿›è¡Œå®šé‡åˆ†æ
- åˆ›å»ºæ•°æ®å¯è§†åŒ–å’Œå›¾è¡¨
- æ‰§è¡Œå¤æ‚çš„ç»Ÿè®¡è®¡ç®—
- ç”Ÿæˆè‡ªå®šä¹‰åˆ†æè„šæœ¬

### 6. ç½‘é¡µå†…å®¹æ·±åº¦åˆ†æ (ä½¿ç”¨ fetch_content å·¥å…·)
- æŠ“å–é‡è¦æŠ€æœ¯åšå®¢å’Œæ–‡æ¡£å†…å®¹
- åˆ†æå®˜æ–¹å‘å¸ƒå’ŒæŠ€æœ¯è§„æ ¼
- æå–å…³é”®æŠ€æœ¯ç»†èŠ‚

### 7. ç»¼åˆæŠ¥å‘Šç”Ÿæˆ (ä½¿ç”¨æ–‡ä»¶ç³»ç»Ÿå·¥å…·)
- åˆ›å»ºç»“æ„åŒ–çš„ç ”ç©¶æŠ¥å‘Š
- æ•´åˆæ‰€æœ‰æ”¶é›†çš„ä¿¡æ¯
- æä¾›æ•°æ®æ”¯æ’‘çš„ç»“è®ºå’Œå»ºè®®

### 8. æ‰§è¡Œè¦æ±‚
- ä½¿ç”¨çœŸå®çš„APIå’Œæ•°æ®æº
- æä¾›å¯éªŒè¯çš„ä¿¡æ¯æ¥æº
- ä¿æŒå®¢è§‚å’Œä¸“ä¸šçš„åˆ†æè§†è§’
- ç¡®ä¿ç ”ç©¶çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
- å……åˆ†åˆ©ç”¨ä»£ç æ‰§è¡Œèƒ½åŠ›è¿›è¡Œå®šé‡åˆ†æ

è¯·ä¸¥æ ¼æŒ‰ç…§Deep Agentçš„æœ€ä½³å®è·µæ‰§è¡Œï¼š
- ä½¿ç”¨è§„åˆ’å·¥å…·ç®¡ç†ä»»åŠ¡è¿›åº¦
- å……åˆ†åˆ©ç”¨æ‰€æœ‰å¯ç”¨çš„çœŸå®å·¥å…·
- åˆ›å»ºè¯¦ç»†çš„æ–‡æ¡£è®°å½•
- æä¾›å…¨é¢çš„ç ”ç©¶æˆæœ

å¼€å§‹æ‰§è¡Œç ”ç©¶ä»»åŠ¡ã€‚
    """
    
    print(f"ğŸš€ å¼€å§‹å…¨é¢ç ”ç©¶: {topic}")
    print("=" * 80)
    
    try:
        # æ‰§è¡Œç ”ç©¶
        result = await agent.run(research_task)
        
        print("\nâœ… ç ”ç©¶ä»»åŠ¡å®Œæˆ!")
        print("=" * 80)
        print(result)
        
        print(f"\nğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
        print(f"æ‰§è¡Œæ­¥æ•°: {agent.current_step}/{agent.max_steps}")
        print(f"æ¶ˆæ¯æ•°é‡: {len(agent.memory.messages)}")
        
        # æ£€æŸ¥è™šæ‹Ÿæ–‡ä»¶ç³»ç»Ÿä¸­çš„æ–‡ä»¶
        if hasattr(agent, 'available_tools'):
            for tool in agent.available_tools.tools:
                if hasattr(tool, 'filesystem') and tool.filesystem._files:
                    print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
                    for filename, content in tool.filesystem._files.items():
                        print(f"â€¢ {filename}: {len(content)} å­—ç¬¦")
                    break
        
        return True
        
    except Exception as e:
        print(f"âŒ ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


async def run_specific_tool_test():
    """è¿è¡Œç‰¹å®šå·¥å…·æµ‹è¯•"""
    
    print("ğŸ§ª å·¥å…·åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•æ™ºèƒ½ä½“
    from myagent.tool.web_search import WebSearchTool
    
    try:
        search_tool = WebSearchTool()
        print("âœ… SERPER æœç´¢å·¥å…·åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æœç´¢
        result = await search_tool.execute("LLM language models 2024", max_results=5)
        
        if result.error:
            print(f"âŒ æœç´¢æµ‹è¯•å¤±è´¥: {result.error}")
        else:
            print(f"âœ… æœç´¢æµ‹è¯•æˆåŠŸ: {result.system}")
            print(f"ğŸ“„ ç»“æœé¢„è§ˆ: {result.output[:200]}...")
            
    except Exception as e:
        print(f"âŒ å·¥å…·æµ‹è¯•å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    
    parser = argparse.ArgumentParser(description='ç ”ç©¶æ™ºèƒ½ä½“æ¼”ç¤º')
    parser.add_argument('--topic', default='LLMçš„å‘å±•å†ç¨‹', help='ç ”ç©¶ä¸»é¢˜')
    parser.add_argument('--test-tools', action='store_true', help='ä»…æµ‹è¯•å·¥å…·åŠŸèƒ½')
    args = parser.parse_args()
    
    print("ğŸ¤– Deep Agents - ç ”ç©¶æ™ºèƒ½ä½“")
    print(f"ğŸ“… å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”‘ API Keys çŠ¶æ€:")
    print(f"  â€¢ SERPER_API_KEY: {'âœ… å·²é…ç½®' if os.getenv('SERPER_API_KEY') else 'âŒ æœªé…ç½®'}")
    print(f"  â€¢ OPENAI_API_KEY: {'âœ… å·²é…ç½®' if os.getenv('OPENAI_API_KEY') else 'âŒ æœªé…ç½®'}")
    print()
    
    if args.test_tools:
        await run_specific_tool_test()
        return
    
    # è¿è¡Œå®Œæ•´ç ”ç©¶æ¼”ç¤º
    success = await run_comprehensive_research(args.topic)
    
    print("\n" + "=" * 80)
    if success:
        print("ğŸ‰ ç ”ç©¶æ™ºèƒ½ä½“æ¼”ç¤ºæˆåŠŸ!")
        print("\nğŸ† æˆåŠŸéªŒè¯çš„èƒ½åŠ›:")
        print("âœ… ç½‘ç»œæœç´¢ï¼šSERPER API é›†æˆ")
        print("âœ… å­¦æœ¯æ–‡çŒ®æœç´¢ï¼šarXiv å’Œ PubMed API")
        print("âœ… æ•°æ®ç§‘å­¦åˆ†æï¼špandas å’Œ numpy")
        print("âœ… ç½‘é¡µå†…å®¹æŠ“å–ï¼šBeautifulSoup è§£æ")
        print("âœ… ä»£ç æ‰§è¡Œï¼šPython ä»£ç åŠ¨æ€æ‰§è¡Œ")
        print("âœ… Deep Agents æ¶æ„ï¼šè§„åˆ’ã€æ–‡ä»¶ç³»ç»Ÿã€å­æ™ºèƒ½ä½“")
        print("âœ… çœŸå®æ•°æ®æºï¼šå¯éªŒè¯çš„ä¿¡æ¯æ¥æº")
        
        print(f"\nğŸ’¡ å®Œæ•´åŠŸèƒ½æ¼”ç¤º: uv run python examples/research_agent_demo.py --topic 'your_topic'")
        print(f"ğŸ’¡ å·¥å…·æµ‹è¯•æ¨¡å¼: uv run python examples/research_agent_demo.py --test-tools")
    else:
        print("âŒ æ¼”ç¤ºæœªå®Œå…¨æˆåŠŸï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥")
        print("\nğŸ”§ æ•…éšœæ’é™¤:")
        print("1. æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ API å¯†é’¥")
        print("2. ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸")
        print("3. éªŒè¯æ‰€æœ‰ä¾èµ–é¡¹å·²å®‰è£…")


if __name__ == "__main__":
    asyncio.run(main())